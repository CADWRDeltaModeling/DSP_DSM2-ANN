{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:46:57.163783800Z",
     "start_time": "2023-06-16T18:46:57.146783500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "local_root_path = \".\"\n",
    "\n",
    "sys.path.append(local_root_path)\n",
    "import annutils\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# find all the .xlsx files in the local_root_path dir\n",
    "excel_files = [f for f in os.listdir(local_root_path) if f.endswith(\".xlsx\") and not f.startswith(\"~$\")]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:05:39.125623900Z",
     "start_time": "2023-06-16T18:05:39.109625900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to turn the excel sheets into inputs we can predict on we need to setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_sheets = 9\n",
    "\n",
    "observed_stations_ordered_by_median = ['RSMKL008', 'RSAN032', 'RSAN037', 'RSAC092', 'SLTRM004', 'ROLD024',\n",
    "                                       'CHVCT000', 'RSAN018', 'CHSWP003', 'CHDMC006', 'SLDUT007', 'RSAN072',\n",
    "                                       'OLD_MID', 'RSAN058', 'ROLD059', 'RSAN007', 'RSAC081', 'SLMZU025',\n",
    "                                       'RSAC075', 'SLMZU011', 'SLSUS012', 'SLCBN002', 'RSAC064']\n",
    "\n",
    "output_stations = ['CHDMC006-CVP INTAKE', 'CHSWP003-CCFB_INTAKE', 'CHVCT000-VICTORIA INTAKE',\n",
    "                   'OLD_MID-OLD RIVER NEAR MIDDLE RIVER', 'ROLD024-OLD RIVER AT BACON ISLAND',\n",
    "                   'ROLD059-OLD RIVER AT TRACY BLVD', 'RSAC064-SACRAMENTO R AT PORT CHICAGO',\n",
    "                   'RSAC075-MALLARDISLAND', 'RSAC081-COLLINSVILLE', 'RSAC092-EMMATON',\n",
    "                   'RSAC101-SACRAMENTO R AT RIO VISTA', 'RSAN007-ANTIOCH', 'RSAN018-JERSEYPOINT',\n",
    "                   'RSAN032-SACRAMENTO R AT SAN ANDREAS LANDING', 'RSAN037-SAN JOAQUIN R AT PRISONERS POINT',\n",
    "                   'RSAN058-ROUGH AND READY ISLAND', 'RSAN072-SAN JOAQUIN R AT BRANDT BRIDGE',\n",
    "                   'RSMKL008-S FORK MOKELUMNE AT TERMINOUS', 'SLCBN002-CHADBOURNE SLOUGH NR SUNRISE DUCK CLUB',\n",
    "                   'SLDUT007-DUTCH SLOUGH', 'SLMZU011-MONTEZUMA SL AT BELDONS LANDING',\n",
    "                   'SLMZU025-MONTEZUMA SL AT NATIONAL STEEL', 'SLSUS012-SUISUN SL NEAR VOLANTI SL',\n",
    "                   'SLTRM004-THREE MILE SLOUGH NR SAN JOAQUIN R', 'SSS-STEAMBOAT SL', 'CCW-MIDDLE RIVER INTAKE',\n",
    "                   'OH4-OLD R @ HWY 4', 'SLRCK005-CCWD_Rock', 'MRU-MIDDLE RIVER AT UNDINE ROAD', 'HLL-HOLLAND TRACT',\n",
    "                   'BET-PIPER SLOUGH @ BETHEL TRACT', 'GES-SACRAMENTO R BELOW GEORGIANA SLOUGH',\n",
    "                   'NMR: N FORK MOKELUMNE R NEAR WALNUT GROVE', 'IBS-CORDELIA SLOUGH @ IBIS CLUB',\n",
    "                   'GYS-GOODYEAR SLOUGH AT MORROW ISLAND CLUB', 'BKS-SLBAR002-North Bay Aqueduct/Barker Sl']\n",
    "\n",
    "output_stations, name_mapping = annutils.read_output_stations(output_stations, observed_stations_ordered_by_median)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:04:53.420107700Z",
     "start_time": "2023-06-16T18:04:53.401107400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def mse_loss_masked(y_true, y_pred):\n",
    "    squared_diff = tf.reduce_sum(tf.math.squared_difference(y_pred[y_true > 0], y_true[y_true > 0]))\n",
    "    return squared_diff / (tf.reduce_sum(tf.cast(y_true > 0, tf.float32)) + 0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:27:39.975310200Z",
     "start_time": "2023-06-16T18:27:39.957309500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def predict(location, df_input, output_columns):\n",
    "    model=keras.models.load_model('%s.h5'%location,custom_objects={\"mse_loss_masked\": mse_loss_masked})\n",
    "    xscaler,yscaler=joblib.load('%s_xyscaler.dump'%location)\n",
    "    return predict_with_model(model, xscaler, yscaler, df_input, output_columns)\n",
    "\n",
    "def predict_with_model(model, xscaler, yscaler, df_input, output_columns):\n",
    "    dfx = pd.DataFrame(xscaler.transform(df_input), df_input.index, columns=df_input.columns)\n",
    "\n",
    "    yyp=model.predict(dfx, verbose=True)\n",
    "    predicted_y = yscaler.inverse_transform(yyp)\n",
    "    return pd.DataFrame(predicted_y, index=df_input.index, columns=output_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T19:28:37.979678Z",
     "start_time": "2023-06-16T19:28:37.970679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 8s 25ms/step\n",
      "338/338 [==============================] - 11s 31ms/step\n",
      "338/338 [==============================] - 9s 27ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 8s 25ms/step\n",
      "338/338 [==============================] - 14s 42ms/step\n",
      "338/338 [==============================] - 13s 38ms/step\n",
      "338/338 [==============================] - 6s 17ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 8s 25ms/step\n",
      "338/338 [==============================] - 10s 31ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 4s 13ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 9s 25ms/step\n",
      "338/338 [==============================] - 10s 30ms/step\n",
      "338/338 [==============================] - 9s 27ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 8s 24ms/step\n",
      "338/338 [==============================] - 10s 30ms/step\n",
      "338/338 [==============================] - 9s 27ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 9s 27ms/step\n",
      "338/338 [==============================] - 8s 24ms/step\n",
      "338/338 [==============================] - 16s 47ms/step\n",
      "338/338 [==============================] - 17s 49ms/step\n",
      "338/338 [==============================] - 8s 23ms/step\n",
      "338/338 [==============================] - 9s 28ms/step\n",
      "338/338 [==============================] - 8s 25ms/step\n",
      "338/338 [==============================] - 11s 31ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 4s 13ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 9s 26ms/step\n",
      "338/338 [==============================] - 11s 32ms/step\n",
      "338/338 [==============================] - 10s 30ms/step\n",
      "338/338 [==============================] - 5s 13ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 8s 24ms/step\n",
      "338/338 [==============================] - 10s 30ms/step\n",
      "338/338 [==============================] - 9s 27ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 8s 24ms/step\n",
      "338/338 [==============================] - 11s 31ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 10s 30ms/step\n",
      "338/338 [==============================] - 9s 25ms/step\n",
      "338/338 [==============================] - 11s 33ms/step\n",
      "338/338 [==============================] - 9s 28ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 10s 29ms/step\n",
      "338/338 [==============================] - 8s 25ms/step\n",
      "338/338 [==============================] - 10s 31ms/step\n",
      "338/338 [==============================] - 14s 43ms/step\n",
      "338/338 [==============================] - 5s 15ms/step\n",
      "338/338 [==============================] - 13s 39ms/step\n",
      "338/338 [==============================] - 13s 37ms/step\n",
      "338/338 [==============================] - 15s 45ms/step\n",
      "338/338 [==============================] - 14s 40ms/step\n",
      "338/338 [==============================] - 6s 17ms/step\n",
      "225/225 [==============================] - 10s 42ms/step\n",
      "225/225 [==============================] - 9s 39ms/step\n",
      "225/225 [==============================] - 12s 55ms/step\n",
      "225/225 [==============================] - 9s 41ms/step\n",
      "225/225 [==============================] - 4s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "experiment = \"6yearsAugmented\"\n",
    "\n",
    "experiment_dir = os.path.join(local_root_path, \"Experiments\", experiment)\n",
    "\n",
    "ndays = 118\n",
    "window_size = 0\n",
    "nwindows = 0\n",
    "\n",
    "compression_opts = dict(method='zip', archive_name='out.csv')\n",
    "\n",
    "model_dir = os.path.join(experiment_dir, \"models\")\n",
    "model_files = [f for f in os.listdir(model_dir) if f.endswith(\".h5\")]\n",
    "\n",
    "\n",
    "for data_file in excel_files:\n",
    "    data_path = os.path.join(local_root_path,data_file)\n",
    "    dfinps, dfouts = annutils.read_and_split(data_path, num_sheets, observed_stations_ordered_by_median)\n",
    "    # may not have to do this...\n",
    "    dfinps = annutils.create_antecedent_inputs(dfinps,ndays=ndays,window_size=window_size,nwindows=nwindows)\n",
    "    dfinps, dfouts = annutils.synchronize(dfinps, dfouts)\n",
    "\n",
    "    #get the name of the file without the extension\n",
    "    file_name = os.path.splitext(data_file)[0]\n",
    "\n",
    "    dirs = [\"input\", \"target\", \"prediction\"]\n",
    "    for dir in dirs:\n",
    "        os.makedirs(os.path.join(\"Experiments\", experiment, \"results\", dir), exist_ok=True)\n",
    "\n",
    "    input_file = os.path.join(\"Experiments\", experiment, \"results\", \"input\", file_name + \".csv\")\n",
    "    dfinps.to_csv(input_file, compression=compression_opts)\n",
    "\n",
    "    # read_in = pd.read_csv(input_file, compression=compression_opts, index_col=0)\n",
    "\n",
    "    target_file = os.path.join(\"Experiments\", experiment, \"results\", \"target\", file_name + \"_target.csv\")\n",
    "    dfouts.to_csv(target_file, compression=compression_opts)\n",
    "\n",
    "\n",
    "    for model_file in model_files:\n",
    "        model_name = os.path.splitext(model_file)[0]\n",
    "\n",
    "        model_prediction_dir = os.path.join(experiment_dir, \"results\", \"prediction\", model_name)\n",
    "        os.makedirs(model_prediction_dir, exist_ok=True)\n",
    "\n",
    "        location = os.path.join(model_dir, model_name)\n",
    "        prediction = predict(location, dfinps, dfouts.columns)\n",
    "        prediction_file = os.path.join(model_prediction_dir, file_name + \".csv\")\n",
    "        prediction.to_csv(prediction_file, compression=compression_opts)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T20:53:15.867110900Z",
     "start_time": "2023-06-16T20:36:59.182521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T19:26:50.214118100Z",
     "start_time": "2023-06-16T19:26:50.199118100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 10s 29ms/step\n",
      "338/338 [==============================] - 9s 26ms/step\n",
      "338/338 [==============================] - 11s 32ms/step\n",
      "338/338 [==============================] - 10s 28ms/step\n",
      "338/338 [==============================] - 4s 12ms/step\n",
      "338/338 [==============================] - 124s 368ms/step\n"
     ]
    }
   ],
   "source": [
    "# find the models\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T19:36:45.962786100Z",
     "start_time": "2023-06-16T19:33:50.304756900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T18:53:57.033998900Z",
     "start_time": "2023-06-16T18:53:57.009998300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
