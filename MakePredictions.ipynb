{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:54:32.146680300Z",
     "start_time": "2023-06-27T18:54:32.134679300Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "local_root_path = \".\"\n",
    "\n",
    "sys.path.append(local_root_path)\n",
    "import annutils\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# excel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:54:37.535209100Z",
     "start_time": "2023-06-27T18:54:37.514451800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# find all the .xlsx files in the local_root_path dir\n",
    "excel_files = [f for f in os.listdir(local_root_path) if f.endswith(\".xlsx\") and not f.startswith(\"~$\")]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup stations\n",
    "In order to turn the excel sheets into inputs we can predict on we need to setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:54:40.283853600Z",
     "start_time": "2023-06-27T18:54:40.275836Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_sheets = 9\n",
    "\n",
    "observed_stations_ordered_by_median = ['RSMKL008', 'RSAN032', 'RSAN037', 'RSAC092', 'SLTRM004', 'ROLD024',\n",
    "                                       'CHVCT000', 'RSAN018', 'CHSWP003', 'CHDMC006', 'SLDUT007', 'RSAN072',\n",
    "                                       'OLD_MID', 'RSAN058', 'ROLD059', 'RSAN007', 'RSAC081', 'SLMZU025',\n",
    "                                       'RSAC075', 'SLMZU011', 'SLSUS012', 'SLCBN002', 'RSAC064']\n",
    "\n",
    "output_stations = ['CHDMC006-CVP INTAKE', 'CHSWP003-CCFB_INTAKE', 'CHVCT000-VICTORIA INTAKE',\n",
    "                   'OLD_MID-OLD RIVER NEAR MIDDLE RIVER', 'ROLD024-OLD RIVER AT BACON ISLAND',\n",
    "                   'ROLD059-OLD RIVER AT TRACY BLVD', 'RSAC064-SACRAMENTO R AT PORT CHICAGO',\n",
    "                   'RSAC075-MALLARDISLAND', 'RSAC081-COLLINSVILLE', 'RSAC092-EMMATON',\n",
    "                   'RSAC101-SACRAMENTO R AT RIO VISTA', 'RSAN007-ANTIOCH', 'RSAN018-JERSEYPOINT',\n",
    "                   'RSAN032-SACRAMENTO R AT SAN ANDREAS LANDING', 'RSAN037-SAN JOAQUIN R AT PRISONERS POINT',\n",
    "                   'RSAN058-ROUGH AND READY ISLAND', 'RSAN072-SAN JOAQUIN R AT BRANDT BRIDGE',\n",
    "                   'RSMKL008-S FORK MOKELUMNE AT TERMINOUS', 'SLCBN002-CHADBOURNE SLOUGH NR SUNRISE DUCK CLUB',\n",
    "                   'SLDUT007-DUTCH SLOUGH', 'SLMZU011-MONTEZUMA SL AT BELDONS LANDING',\n",
    "                   'SLMZU025-MONTEZUMA SL AT NATIONAL STEEL', 'SLSUS012-SUISUN SL NEAR VOLANTI SL',\n",
    "                   'SLTRM004-THREE MILE SLOUGH NR SAN JOAQUIN R', 'SSS-STEAMBOAT SL', 'CCW-MIDDLE RIVER INTAKE',\n",
    "                   'OH4-OLD R @ HWY 4', 'SLRCK005-CCWD_Rock', 'MRU-MIDDLE RIVER AT UNDINE ROAD', 'HLL-HOLLAND TRACT',\n",
    "                   'BET-PIPER SLOUGH @ BETHEL TRACT', 'GES-SACRAMENTO R BELOW GEORGIANA SLOUGH',\n",
    "                   'NMR: N FORK MOKELUMNE R NEAR WALNUT GROVE', 'IBS-CORDELIA SLOUGH @ IBIS CLUB',\n",
    "                   'GYS-GOODYEAR SLOUGH AT MORROW ISLAND CLUB', 'BKS-SLBAR002-North Bay Aqueduct/Barker Sl']\n",
    "\n",
    "output_stations, name_mapping = annutils.read_output_stations(output_stations, observed_stations_ordered_by_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mse_loss_masked def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:54:46.785824200Z",
     "start_time": "2023-06-27T18:54:46.781823Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse_loss_masked(y_true, y_pred):\n",
    "    squared_diff = tf.reduce_sum(tf.math.squared_difference(y_pred[y_true > 0], y_true[y_true > 0]))\n",
    "    return squared_diff / (tf.reduce_sum(tf.cast(y_true > 0, tf.float32)) + 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T18:54:50.822869600Z",
     "start_time": "2023-06-27T18:54:50.817511900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(location, df_input, output_columns):\n",
    "    model=keras.models.load_model('%s.h5'%location,custom_objects={\"mse_loss_masked\": mse_loss_masked})\n",
    "    xscaler,yscaler=joblib.load('%s_xyscaler.dump'%location)\n",
    "    return predict_with_model(model, xscaler, yscaler, df_input, output_columns)\n",
    "\n",
    "def predict_with_model(model, xscaler, yscaler, df_input, output_columns):\n",
    "    dfx = pd.DataFrame(xscaler.transform(df_input), df_input.index, columns=df_input.columns)\n",
    "\n",
    "    yyp=model.predict(dfx, verbose=True)\n",
    "    predicted_y = yscaler.inverse_transform(yyp)\n",
    "    return pd.DataFrame(predicted_y, index=df_input.index, columns=output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T21:39:09.020533Z",
     "start_time": "2023-06-27T21:34:40.150531Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 4years_cal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: dsm2_ann_inputs_base.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file: mtl_i118_residual_lstm_8_2.h5\n",
      "Location: .\\Experiments\\4years_cal\\models\\mtl_i118_residual_lstm_8_2\n",
      "Xscaler Min[0]: 4305.58333396911\n",
      "Xscaler Max[0]: 82406.1875\n",
      "338/338 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: dsm2_ann_inputs_dcc0.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file: mtl_i118_residual_lstm_8_2.h5\n",
      "Location: .\\Experiments\\4years_cal\\models\\mtl_i118_residual_lstm_8_2\n",
      "Xscaler Min[0]: 4305.58333396911\n",
      "Xscaler Max[0]: 82406.1875\n",
      "338/338 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: dsm2_ann_inputs_dcc1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:38<03:52, 19.37s/it]\n",
      "  0%|          | 0/1 [00:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\projects\\delta_salinity\\scripts\\rma_ann_repo\\MakePredictions.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/delta_salinity/scripts/rma_ann_repo/MakePredictions.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mExperiments\u001b[39m\u001b[39m\"\u001b[39m, experiment, \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mdir\u001b[39m), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/delta_salinity/scripts/rma_ann_repo/MakePredictions.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m input_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mExperiments\u001b[39m\u001b[39m\"\u001b[39m, experiment, \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m, file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/projects/delta_salinity/scripts/rma_ann_repo/MakePredictions.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m dfinps\u001b[39m.\u001b[39;49mto_csv(input_file, compression\u001b[39m=\u001b[39;49mcompression_opts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/delta_salinity/scripts/rma_ann_repo/MakePredictions.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# read_in = pd.read_csv(input_file, compression=compression_opts, index_col=0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/projects/delta_salinity/scripts/rma_ann_repo/MakePredictions.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m target_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mExperiments\u001b[39m\u001b[39m\"\u001b[39m, experiment, \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m, file_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_target.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[0;32m    303\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    312\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[0;32m    314\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[1;32m--> 315\u001b[0m libwriters\u001b[39m.\u001b[39;49mwrite_csv_rows(\n\u001b[0;32m    316\u001b[0m     data,\n\u001b[0;32m    317\u001b[0m     ix,\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlevels,\n\u001b[0;32m    319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols,\n\u001b[0;32m    320\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter,\n\u001b[0;32m    321\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\pandas\\_libs\\writers.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\codecs.py:328\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 328\u001b[0m     IncrementalDecoder\u001b[39m.\u001b[39mreset(\u001b[39mself\u001b[39m)\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiments = [\"lathypcub_regtide\"]  #\"colab\",\"6years\", \"6yearsAugmented\", \"4years\",\"4years_DCC\",\"4years_SacLag\",\"4years_SacMag\",\"colab_wo2015\"\n",
    "\n",
    "for experiment in tqdm(experiments):\n",
    "    print(\"Experiment: %s\" % experiment)\n",
    "    experiment_dir = os.path.join(local_root_path, \"Experiments\", experiment)\n",
    "\n",
    "    ndays = 118\n",
    "    window_size = 0\n",
    "    nwindows = 0\n",
    "\n",
    "    compression_opts = dict(method='zip', archive_name='out.csv')\n",
    "\n",
    "    model_dir = os.path.join(experiment_dir, \"models\")\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith(\".h5\")]\n",
    "\n",
    "\n",
    "    for data_file in tqdm(excel_files):\n",
    "        print(\"Data file: %s\" % data_file)\n",
    "        data_path = os.path.join(local_root_path,data_file)\n",
    "        dfinps, dfouts = annutils.read_and_split(data_path, num_sheets, observed_stations_ordered_by_median)\n",
    "\n",
    "        dfinps = annutils.create_antecedent_inputs(dfinps,ndays=ndays,window_size=window_size,nwindows=nwindows)\n",
    "        dfinps, dfouts = annutils.synchronize(dfinps, dfouts)\n",
    "\n",
    "        #get the name of the file without the extension\n",
    "        file_name = os.path.splitext(data_file)[0]\n",
    "\n",
    "        dirs = [\"input\", \"target\", \"prediction\"]\n",
    "        for dir in dirs:\n",
    "            os.makedirs(os.path.join(\"Experiments\", experiment, \"results\", dir), exist_ok=True)\n",
    "\n",
    "        input_file = os.path.join(\"Experiments\", experiment, \"results\", \"input\", file_name + \".csv\")\n",
    "        dfinps.to_csv(input_file, compression=compression_opts)\n",
    "\n",
    "        # read_in = pd.read_csv(input_file, compression=compression_opts, index_col=0)\n",
    "\n",
    "        target_file = os.path.join(\"Experiments\", experiment, \"results\", \"target\", file_name + \"_target.csv\")\n",
    "        dfouts.to_csv(target_file, compression=compression_opts)\n",
    "\n",
    "        for model_file in tqdm(model_files):\n",
    "            print(\"Model file: %s\" % model_file)\n",
    "            model_name = os.path.splitext(model_file)[0]\n",
    "\n",
    "            model_prediction_dir = os.path.join(experiment_dir, \"results\", \"prediction\", model_name)\n",
    "            os.makedirs(model_prediction_dir, exist_ok=True)\n",
    "\n",
    "            location = os.path.join(model_dir, model_name)\n",
    "            print(\"Location: %s\" % location)\n",
    "            #prediction = predict(location, dfinps, dfouts.columns)\n",
    "            model=keras.models.load_model('%s.h5'%location,custom_objects={\"mse_loss_masked\": mse_loss_masked})\n",
    "            xscaler,yscaler=joblib.load('%s_xyscaler.dump'%location)\n",
    "            print(\"Xscaler Min[0]: %s\" % xscaler.min_val[0])\n",
    "            print(\"Xscaler Max[0]: %s\" % xscaler.max_val[0])\n",
    "            scaled_input = xscaler.transform(dfinps)\n",
    "            dfx = pd.DataFrame(scaled_input, dfinps.index, columns=dfinps.columns)\n",
    "\n",
    "            yyp=model.predict(dfx, verbose=True)\n",
    "            predicted_y = yscaler.inverse_transform(yyp)\n",
    "            prediction = pd.DataFrame(predicted_y, index=dfinps.index, columns=dfouts.columns)\n",
    "            prediction_file = os.path.join(model_prediction_dir, file_name + \".csv\")\n",
    "            prediction.to_csv(prediction_file, compression=compression_opts)\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
