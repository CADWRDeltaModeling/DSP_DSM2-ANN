{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.821349800Z",
     "start_time": "2023-06-27T20:38:17.798348600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.851138900Z",
     "start_time": "2023-06-27T20:38:17.809348700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomkovic\\Miniconda3\\envs\\Salinity_DWR\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "local_root_path = \".\"\n",
    "\n",
    "sys.path.append(local_root_path)\n",
    "import annutils\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.858137300Z",
     "start_time": "2023-06-27T20:38:17.825349800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_lr = 0.001\n",
    "\n",
    "'''\n",
    "Dropout ratio at (before) the input layer\n",
    "'''\n",
    "input_dropout = 0.\n",
    "\n",
    "'''\n",
    "Dropout ratio at intermediate layers\n",
    "'''\n",
    "intermediate_dropout = 0\n",
    "\n",
    "ndays=118\n",
    "window_size=0\n",
    "nwindows=0\n",
    "num_sheets = 9\n",
    "\n",
    "compression_opts = dict(method='zip', archive_name='out.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build_model_string def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.858137300Z",
     "start_time": "2023-06-27T20:38:17.851138900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model_string(model_type, num_neurons_multiplier, input_dropout=0, intermediate_dropout=0):\n",
    "    model_type = model_type.lower()\n",
    "    model_str_def = None\n",
    "    if model_type == 'mlp':\n",
    "        ## 1. MLP Network\n",
    "        model_str_def = '%sd%d_%sd%d_o1' % (('dr%.2f_' % input_dropout if input_dropout > 0 else ''),\n",
    "                                            num_neurons_multiplier[0],\n",
    "                                            ('dr%.2f_' % intermediate_dropout if intermediate_dropout > 0 else ''),\n",
    "                                            num_neurons_multiplier[1])\n",
    "\n",
    "    elif model_type == 'lstm':\n",
    "        # 2. LSTM Network\n",
    "        model_str_def = '%slstm%d_%sf_o1' % (('dr%.2f_' % input_dropout if input_dropout > 0 else ''),\n",
    "                                             num_neurons_multiplier[0],\n",
    "                                             ('dr%.2f_' % intermediate_dropout if intermediate_dropout > 0 else ''),)\n",
    "\n",
    "    elif model_type == 'gru':\n",
    "        # 3. GRU Network\n",
    "        model_str_def = '%sg%d_%sf_o1' % (('dr%.2f_' % input_dropout if input_dropout > 0 else ''),\n",
    "                                          num_neurons_multiplier[0],\n",
    "                                          ('dr%.2f_' % intermediate_dropout if intermediate_dropout > 0 else ''),)\n",
    "\n",
    "    elif model_type == 'resnet':\n",
    "        # 4. ResNet\n",
    "        if intermediate_dropout > 0:\n",
    "            num_neurons_multiplier.insert(1, 'dr%.2f' % intermediate_dropout)\n",
    "        model_str_def = '%sresnet%s' % (('dr%.2f_' % input_dropout if input_dropout > 0 else ''),\n",
    "                                        '_' + '_'.join([str(ii) for ii in num_neurons_multiplier]))\n",
    "        num_res_blocks = 1\n",
    "\n",
    "    elif model_type == 'res-lstm':\n",
    "        # 5. Res-LSTM\n",
    "        if intermediate_dropout > 0:\n",
    "            num_neurons_multiplier.insert(1, 'dr%.2f' % intermediate_dropout)\n",
    "        model_str_def = '%sresidual_lstm%s' % (('dr%.2f_' % input_dropout if input_dropout > 0 else ''),\n",
    "                                               '_' + '_'.join([str(ii) for ii in num_neurons_multiplier]))\n",
    "\n",
    "    elif model_type == 'res-gru':\n",
    "        # 6. Res-GRU\n",
    "        if intermediate_dropout > 0:\n",
    "            num_neurons_multiplier.insert(1, 'dr%.2f' % intermediate_dropout)\n",
    "        model_str_def = '%sresidual_gru%s' % (('dr%.2f_' % input_dropout if input_dropout > 0 else ''),\n",
    "                                              '_' + '_'.join([str(ii) for ii in num_neurons_multiplier]))\n",
    "\n",
    "    elif model_type == 'transformer':        # 7. Transformer\n",
    "        model_str_def = '%stransformer' % ('dr%.2f_' % input_dropout if input_dropout > 0 else '')\n",
    "\n",
    "    return model_str_def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorboard stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.869138100Z",
     "start_time": "2023-06-27T20:38:17.855140400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./tf_training_logs/ --port=6006\n",
    "now = datetime.now()\n",
    "root_logdir = os.path.join(os.curdir, \"tf_training_logs\", now.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(root_logdir)  ## Tensorflow Board Setup\n",
    "###############"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ANN Specific Definitions\n",
    "Next cell is a bunch of ann specific defs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.932138900Z",
     "start_time": "2023-06-27T20:38:17.871139500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"kernel_initializer\": \"he_normal\"\n",
    "}\n",
    "\n",
    "def basic_1d(\n",
    "        filters,\n",
    "        stage=0,\n",
    "        block=0,\n",
    "        kernel_size=3,\n",
    "        numerical_name=False,\n",
    "        stride=None,\n",
    "        force_identity_shortcut=False\n",
    "):\n",
    "    \"\"\"\n",
    "    A one-dimensional basic block.\n",
    "    :param filters: the output’s feature space\n",
    "    :param stage: int representing the stage of this block (starting from 0)\n",
    "    :param block: int representing this block (starting from 0)\n",
    "    :param kernel_size: size of the kernel\n",
    "    :param numerical_name: if true, uses numbers to represent blocks instead of chars (ResNet{101, 152, 200})\n",
    "    :param stride: int representing the stride used in the shortcut and the first conv layer, default derives stride from block id\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        if block != 0 or stage == 0:\n",
    "            stride = 1\n",
    "        else:\n",
    "            stride = 2\n",
    "\n",
    "    if block > 0 and numerical_name:\n",
    "        block_char = \"b{}\".format(block)\n",
    "    else:\n",
    "        block_char = chr(ord('a') + block)\n",
    "\n",
    "    stage_char = str(stage + 2)\n",
    "\n",
    "    def f(x):\n",
    "        y = keras.layers.ZeroPadding1D(padding=1, name=\"padding{}{}_branch2a\".format(stage_char, block_char))(x)\n",
    "        y = keras.layers.Conv1D(filters, kernel_size, strides=stride, use_bias=False,\n",
    "                                name=\"res{}{}_branch2a\".format(stage_char, block_char),\n",
    "                                **parameters)(y)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "        y = keras.layers.Activation(\"relu\", name=\"res{}{}_branch2a_relu\".format(stage_char, block_char))(y)\n",
    "\n",
    "        y = keras.layers.ZeroPadding1D(padding=1, name=\"padding{}{}_branch2b\".format(stage_char, block_char))(y)\n",
    "        y = keras.layers.Conv1D(filters, kernel_size, use_bias=False,\n",
    "                                name=\"res{}{}_branch2b\".format(stage_char, block_char),\n",
    "                                **parameters)(y)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "\n",
    "        if block != 0 or force_identity_shortcut:\n",
    "            shortcut = x\n",
    "        else:\n",
    "            shortcut = keras.layers.Conv1D(filters, 1, strides=stride, use_bias=False,\n",
    "                                           name=\"res{}{}_branch1\".format(stage_char, block_char),\n",
    "                                           **parameters)(x)\n",
    "            shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        y = keras.layers.Add(name=\"res{}{}\".format(stage_char, block_char))([y, shortcut])\n",
    "\n",
    "        y = keras.layers.Activation(\"relu\", name=\"res{}{}_relu\".format(stage_char, block_char))(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    return f\n",
    "\n",
    "def bottleneck_1d(\n",
    "        filters,\n",
    "        stage=0,\n",
    "        block=0,\n",
    "        kernel_size=3,\n",
    "        numerical_name=False,\n",
    "        stride=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    A one-dimensional bottleneck block.\n",
    "    :param filters: the output’s feature space\n",
    "    :param stage: int representing the stage of this block (starting from 0)\n",
    "    :param block: int representing this block (starting from 0)\n",
    "    :param kernel_size: size of the kernel\n",
    "    :param numerical_name: if true, uses numbers to represent blocks instead of chars (ResNet{101, 152, 200})\n",
    "    :param stride: int representing the stride used in the shortcut and the first conv layer, default derives stride from block id\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        stride = 1 if block != 0 or stage == 0 else 2\n",
    "\n",
    "    # axis = -1 if keras.backend.image_data_format() == \"channels_last\" else 1\n",
    "\n",
    "    if block > 0 and numerical_name:\n",
    "        block_char = \"b{}\".format(block)\n",
    "    else:\n",
    "        block_char = chr(ord('a') + block)\n",
    "\n",
    "    stage_char = str(stage + 2)\n",
    "\n",
    "    def f(x):\n",
    "        y = keras.layers.Conv1D(filters, 1, strides=stride, use_bias=False,\n",
    "                                name=\"res{}{}_branch2a\".format(stage_char, block_char),\n",
    "                                **parameters)(x)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "        y = keras.layers.Activation(\"relu\", name=\"res{}{}_branch2a_relu\".format(stage_char, block_char))(y)\n",
    "\n",
    "        y = keras.layers.ZeroPadding1D(padding=1, name=\"padding{}{}_branch2b\".format(stage_char, block_char))(y)\n",
    "        y = keras.layers.Conv1D(filters, kernel_size, use_bias=False,\n",
    "                                name=\"res{}{}_branch2b\".format(stage_char, block_char),\n",
    "                                **parameters)(y)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "        y = keras.layers.Activation(\"relu\", name=\"res{}{}_branch2b_relu\".format(stage_char, block_char))(y)\n",
    "\n",
    "        y = keras.layers.Conv1D(filters * 4, 1, use_bias=False,\n",
    "                                name=\"res{}{}_branch2c\".format(stage_char, block_char),\n",
    "                                **parameters)(y)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "\n",
    "        if block == 0:\n",
    "            shortcut = keras.layers.Conv1D(filters * 4, 1, strides=stride, use_bias=False,\n",
    "                                           name=\"res{}{}_branch1\".format(stage_char, block_char),\n",
    "                                           **parameters)(x)\n",
    "            shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "        else:\n",
    "            shortcut = x\n",
    "\n",
    "        y = keras.layers.Add(name=\"res{}{}\".format(stage_char, block_char))([y, shortcut])\n",
    "        y = keras.layers.Activation(\"relu\", name=\"res{}{}_relu\".format(stage_char, block_char))(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    return f\n",
    "\n",
    "###############\n",
    "\"\"\"# Custom loss function\"\"\"\n",
    "\n",
    "def mse_loss_masked(y_true, y_pred):\n",
    "    squared_diff = tf.reduce_sum(tf.math.squared_difference(y_pred[y_true > 0], y_true[y_true > 0]))\n",
    "    return squared_diff / (tf.reduce_sum(tf.cast(y_true > 0, tf.float32)) + 0.01)\n",
    "\n",
    "# Define Sequential model\n",
    "NFEATURES =  8 #dfinps.shape[1]  # * (ndays + nwindows)\n",
    "\n",
    "def build_layer_from_string_def(s='i120', width_multiplier=1,\n",
    "                                block=0,\n",
    "                                force_identity_shortcut=False,\n",
    "                                return_sequences_rnn=True):\n",
    "    if s[0:4] == 'lstm':\n",
    "        return layers.LSTM(units=int(s[4:]) * width_multiplier, return_sequences=return_sequences_rnn,\n",
    "                           activation='sigmoid')\n",
    "    elif s[0:3] == 'res':\n",
    "        fields = s[3:].split('x')\n",
    "        return basic_1d(filters=int(fields[0]),\n",
    "                        stage=int(fields[3]),\n",
    "                        block=block,\n",
    "                        kernel_size=int(fields[1]),\n",
    "                        stride=int(fields[2]),\n",
    "                        force_identity_shortcut=force_identity_shortcut)\n",
    "    elif s[0:3] == 'c1d':\n",
    "        fields = s[3:].split('x')\n",
    "        return keras.layers.Conv1D(filters=int(fields[0]), kernel_size=int(fields[1]), strides=int(fields[2]),\n",
    "                                   padding='causal', activation='linear')\n",
    "    elif s[0:2] == 'td':\n",
    "        return keras.layers.TimeDistributed(keras.layers.Dense(int(s[2:]), activation='elu'))\n",
    "    elif s[0:2] == 'dr':\n",
    "        return keras.layers.Dropout(float(s[2:]))\n",
    "    # elif s[0] == 'i':\n",
    "    #     return keras.layers.InputLayer(input_shape=[int(s[1:]), NFEATURES])\n",
    "    elif s[0] == 'f':\n",
    "        return keras.layers.Flatten()\n",
    "    elif s[0] == 'g':\n",
    "        return keras.layers.GRU(int(s[1:]) * width_multiplier, return_sequences=True, activation='relu')\n",
    "    elif s[0] == 'd':\n",
    "        return keras.layers.Dense(int(s[1:]) * width_multiplier, activation='elu')\n",
    "    elif s[0] == 'o':\n",
    "        return keras.layers.Dense(int(s[1:]) * width_multiplier, activation='linear')\n",
    "    else:\n",
    "        raise Exception('Unknown layer def: %s' % s)\n",
    "\n",
    "###############\n",
    "\n",
    "def build_model_from_string_def(strdef='i120_f_d4_d2_d1', width_multiplier=1):\n",
    "    layer_strings = strdef.split('_')\n",
    "    print ('layer_strings:%s' % layer_strings)\n",
    "    inputs = keras.layers.Input(shape=[int(layer_strings[0][1:]) * NFEATURES])\n",
    "    x = None\n",
    "    prev_conv_output_num_of_channels = None\n",
    "    return_sequences_rnn = None\n",
    "    for block, f in enumerate(layer_strings[1:-1]):\n",
    "        if x is None:\n",
    "            if ('lstm' in strdef) or ('g' in strdef):\n",
    "                # these layers require 2D inputs and permutation\n",
    "                x = layers.Reshape((ndays + nwindows, NFEATURES))(inputs)\n",
    "                prev_conv_output_num_of_channels = NFEATURES\n",
    "                x = layers.Permute((2, 1))(x)\n",
    "                return_sequences_rnn = layer_strings[block + 2].startswith(('lstm', 'g', 'res', 'c1d'))\n",
    "            elif ('res' in strdef) or ('cld' in strdef):\n",
    "                # these layers require 2D inputs\n",
    "                x = layers.Reshape((ndays + nwindows, NFEATURES))(inputs)\n",
    "                prev_conv_output_num_of_channels = NFEATURES\n",
    "            else:\n",
    "                x = inputs\n",
    "\n",
    "        x = build_layer_from_string_def(f, width_multiplier, block,\n",
    "                                        force_identity_shortcut=(\n",
    "                                                f.startswith('res') and prev_conv_output_num_of_channels == int(\n",
    "                                            f[3:].split('x')[0])),\n",
    "                                        return_sequences_rnn=return_sequences_rnn)(x)\n",
    "        if f.startswith('lstm'):\n",
    "            prev_conv_output_num_of_channels = int(f[4:])\n",
    "        elif f.startswith('res') or f.startswith('c1d'):\n",
    "            prev_conv_output_num_of_channels = int(f[3:].split('x')[0])\n",
    "\n",
    "    outputs = keras.layers.Dense(int(layer_strings[-1][1:]) * width_multiplier, activation='linear')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=initial_lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_resnet_model(nhidden1=8, nhidden2=2, output_shape=1, act_func='sigmoid',\n",
    "                       filters=num_sheets - 1, kernel_size=3, stride=1,\n",
    "                       num_res_blocks=1, input_dropout=0.):\n",
    "    inputs = layers.Input(shape=NFEATURES * (ndays + nwindows))\n",
    "    x = layers.Reshape((ndays + nwindows, NFEATURES))(inputs)\n",
    "    x = layers.Dropout(input_dropout)(x)\n",
    "    for ii in range(num_res_blocks - 1):\n",
    "        # TODO: think about conv filter numbers and kernel sizes\n",
    "        intermediate_features = layers.ZeroPadding1D(padding=1, name=\"padding%d_branch2a\" % ii)(x)\n",
    "        intermediate_features = layers.Conv1D(filters=NFEATURES, kernel_size=2, strides=1, use_bias=False,\n",
    "                                              name=\"res%d_branch2a\" % ii)(intermediate_features)\n",
    "        intermediate_features = layers.BatchNormalization()(intermediate_features)\n",
    "        intermediate_features = layers.Activation(\"relu\", name=\"res%d_branch2a_relu\" % ii)(intermediate_features)\n",
    "\n",
    "        intermediate_features = layers.Conv1D(filters=NFEATURES, kernel_size=2, strides=1, use_bias=False,\n",
    "                                              name=\"res%d_branch2b\" % ii)(intermediate_features)\n",
    "        intermediate_features = layers.BatchNormalization()(intermediate_features)\n",
    "        intermediate_features = layers.Activation(\"relu\", name=\"res%d_branch2b_relu\" % ii)(intermediate_features)\n",
    "\n",
    "        shortcut = x\n",
    "        x = layers.Add(name=\"res%d_add\" % ii)([intermediate_features, shortcut])\n",
    "\n",
    "    y = layers.ZeroPadding1D(padding=1, name=\"padding%d_branch2a\" % num_res_blocks)(x)\n",
    "    y = layers.Conv1D(filters, kernel_size, strides=stride, use_bias=False,\n",
    "                      name=\"res%d_branch2a\" % num_res_blocks)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation(\"relu\", name=\"res%d_branch2a_relu\" % num_res_blocks)(y)\n",
    "\n",
    "    y = layers.ZeroPadding1D(padding=1, name=\"padding%d_branch2b\" % num_res_blocks)(y)\n",
    "    y = layers.Conv1D(filters, kernel_size, use_bias=False,\n",
    "                      name=\"res%d_branch2b\" % num_res_blocks)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(nhidden1, activation=act_func)(y)\n",
    "\n",
    "    shortcut = inputs\n",
    "    shortcut = layers.Dense(nhidden1, activation=act_func)(shortcut)\n",
    "\n",
    "    y = layers.Add(name=\"res%d_add\" % num_res_blocks)([y, shortcut])\n",
    "    y = layers.Dropout(intermediate_dropout)(y)\n",
    "\n",
    "    y = layers.Activation(\"relu\", name=\"res_relu\")(y)\n",
    "\n",
    "    y = layers.Dense(nhidden2, activation=act_func)(y)\n",
    "    outputs = layers.Dense(output_shape, activation=keras.activations.linear, name='output')(y)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=initial_lr), loss=mse_loss_masked)\n",
    "    return model\n",
    "\n",
    "def build_residual_lstm_model(nhidden1=8, nhidden2=2, output_shape=1,\n",
    "                              act_func='sigmoid', layer_type='lstm',\n",
    "                              conv_init=None,\n",
    "                              input_dropout=0.):\n",
    "    rnn_layer = layers.LSTM if layer_type == 'lstm' else layers.GRU\n",
    "    input_shape = NFEATURES * (ndays + nwindows)\n",
    "    print(\"input shape: \", input_shape)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Reshape((ndays + nwindows, NFEATURES))(inputs)\n",
    "    x = layers.Dropout(input_dropout)(x)\n",
    "    x = layers.Permute((2, 1))(x)\n",
    "\n",
    "    y = tf.keras.layers.Conv1D(ndays + nwindows, 1, activation='relu',\n",
    "                               kernel_initializer=conv_init,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0, l2=0),\n",
    "                               trainable=False)(x)\n",
    "\n",
    "    y = layers.Flatten()(y)\n",
    "    y = layers.Dense(nhidden1, activation=act_func)(y)\n",
    "    y = layers.Dropout(intermediate_dropout)(y)\n",
    "    y = layers.Dense(nhidden2, activation=act_func)(y)\n",
    "    y = layers.Dense(output_shape, activation=keras.activations.linear, name='mlp_output')(y)\n",
    "\n",
    "    shortcut = x\n",
    "    shortcut = layers.Dense(nhidden1, activation=act_func)(shortcut)\n",
    "    shortcut = rnn_layer(units=output_shape * 2, activation=act_func, return_sequences=True)(shortcut)\n",
    "    shortcut = layers.Flatten()(shortcut)\n",
    "    shortcut = layers.Dense(output_shape, activation=keras.activations.linear, name='lstm_output')(shortcut)\n",
    "\n",
    "    outputs = layers.Add(name=\"res_add\")([y, shortcut])\n",
    "    # outputs = layers.Activation(\"relu\",name=\"res_relu\")(outputs)\n",
    "    outputs = layers.LeakyReLU(alpha=0.3, name=\"res_relu\")(outputs)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=initial_lr), loss=mse_loss_masked)\n",
    "    return model\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_transformer(head_size,\n",
    "                      num_heads,\n",
    "                      ff_dim,\n",
    "                      num_transformer_blocks,\n",
    "                      mlp_units,\n",
    "                      output_shape,\n",
    "                      dropout=0,\n",
    "                      mlp_dropout=0,\n",
    "                      input_dropout=0):\n",
    "    inputs = keras.Input(shape=NFEATURES * (ndays + nwindows))\n",
    "    x = layers.Reshape((ndays + nwindows, NFEATURES))(inputs)\n",
    "    x = layers.Dropout(input_dropout)(x)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(output_shape)(x)\n",
    "    outputs = layers.LeakyReLU(alpha=0.3, name=\"res_relu\")(outputs)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "        learning_rate=initial_lr), loss=mse_loss_masked)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build_or_load_model def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.947419500Z",
     "start_time": "2023-06-27T20:38:17.939418400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_or_load_model(model_path, model_str_def, num_neurons_multiplier, output_shape  ):\n",
    "    xscaler = None\n",
    "    yscaler = None\n",
    "    if os.path.exists(model_path + '.h5'):\n",
    "        loaded_model = annutils.load_model(model_path,\n",
    "                                           custom_objects={\"mse_loss_masked\": mse_loss_masked})\n",
    "        model = loaded_model.model\n",
    "        xscaler = loaded_model.xscaler\n",
    "        yscaler = loaded_model.yscaler\n",
    "        print('Ignored defined model arc and loaded pre-trained model from %s.h5' % model_path)\n",
    "\n",
    "    len_stations = output_shape[1]\n",
    "    print(\"len_stations: \", len_stations)\n",
    "    if 'resnet' in model_str_def.lower():\n",
    "        num_res_blocks =1\n",
    "        model = build_resnet_model(nhidden1=num_neurons_multiplier[0] * len_stations,\n",
    "                                   nhidden2=num_neurons_multiplier[-1] * len_stations, output_shape=len_stations,\n",
    "                                   num_res_blocks=num_res_blocks,\n",
    "                                   input_dropout=input_dropout)\n",
    "    elif ('residual_lstm' in model_str_def.lower()) or ('residual_gru' in model_str_def.lower()):\n",
    "        print(\"model is lstm or gru\")\n",
    "        print(\"ndays: \", ndays)\n",
    "        print(\"nwindows: \", nwindows)\n",
    "        print(\"window_size: \", window_size)\n",
    "        print(\"output_shape: \", output_shape)\n",
    "        conv_init = tf.constant_initializer(annutils.conv_filter_generator(ndays=ndays,\n",
    "                                                                           window_size=window_size,\n",
    "                                                                           nwindows=nwindows))\n",
    "\n",
    "        layer_type = model_str_def.lower().split('_')[2]\n",
    "        print(\"layer_type: \", layer_type)\n",
    "        model = build_residual_lstm_model(num_neurons_multiplier[0] * len_stations,\n",
    "                                          num_neurons_multiplier[-1] * len_stations,\n",
    "                                          output_shape=len_stations,\n",
    "                                          act_func='sigmoid',\n",
    "                                          layer_type=layer_type,\n",
    "                                          conv_init=conv_init,\n",
    "                                          input_dropout=input_dropout)\n",
    "    elif 'transformer' in model_str_def.lower():\n",
    "        model = build_transformer(head_size=256,\n",
    "                                  num_heads=4,\n",
    "                                  ff_dim=4,\n",
    "                                  num_transformer_blocks=4,\n",
    "                                  mlp_units=[128],\n",
    "                                  output_shape=len_stations,\n",
    "                                  mlp_dropout=0.4,\n",
    "                                  dropout=0.25,\n",
    "                                  input_dropout=input_dropout)\n",
    "    else:\n",
    "        model = build_model_from_string_def(model_str_def, width_multiplier=len_stations)\n",
    "\n",
    "    return model, xscaler, yscaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# plot_history def\n",
    "\n",
    "Now we should be ready to make some models and do some training\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:38:17.980421700Z",
     "start_time": "2023-06-27T20:38:17.966418900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title('model loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN: Train model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T21:31:15.633145500Z",
     "start_time": "2023-06-27T20:39:02.957794Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment:  4years_cal\n",
      "model_str_def: lstm8_f_o1\n",
      "len_stations:  23\n",
      "layer_strings:['i118', 'lstm8', 'f', 'o1']\n",
      "Model summary:\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 944)]             0         \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 118, 8)            0         \n",
      "                                                                 \n",
      " permute_2 (Permute)         (None, 8, 118)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 184)               223008    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 184)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 23)                4255      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,263\n",
      "Trainable params: 227,263\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Creating new scalers\n",
      "Xscaler Min[0]: 4305.58333396911\n",
      "Xscaler Max[0]: 82406.1875\n",
      "Epoch 1/50\n",
      "12/12 - 5s - loss: 0.1378 - val_loss: 0.0934 - 5s/epoch - 381ms/step\n",
      "Epoch 2/50\n",
      "12/12 - 2s - loss: 0.0659 - val_loss: 0.0652 - 2s/epoch - 131ms/step\n",
      "Epoch 3/50\n",
      "12/12 - 2s - loss: 0.0578 - val_loss: 0.0694 - 2s/epoch - 134ms/step\n",
      "Epoch 4/50\n",
      "12/12 - 2s - loss: 0.0533 - val_loss: 0.0631 - 2s/epoch - 131ms/step\n",
      "Epoch 5/50\n",
      "12/12 - 2s - loss: 0.0505 - val_loss: 0.0672 - 2s/epoch - 127ms/step\n",
      "Epoch 6/50\n",
      "12/12 - 1s - loss: 0.0481 - val_loss: 0.0697 - 1s/epoch - 125ms/step\n",
      "Epoch 7/50\n",
      "12/12 - 2s - loss: 0.0466 - val_loss: 0.0794 - 2s/epoch - 127ms/step\n",
      "Epoch 8/50\n",
      "12/12 - 1s - loss: 0.0454 - val_loss: 0.0723 - 1s/epoch - 123ms/step\n",
      "Epoch 9/50\n",
      "12/12 - 2s - loss: 0.0438 - val_loss: 0.0698 - 2s/epoch - 127ms/step\n",
      "Epoch 10/50\n",
      "12/12 - 2s - loss: 0.0428 - val_loss: 0.0715 - 2s/epoch - 129ms/step\n",
      "Epoch 11/50\n",
      "12/12 - 2s - loss: 0.0415 - val_loss: 0.0691 - 2s/epoch - 131ms/step\n",
      "Epoch 12/50\n",
      "12/12 - 2s - loss: 0.0408 - val_loss: 0.0716 - 2s/epoch - 127ms/step\n",
      "Epoch 13/50\n",
      "12/12 - 2s - loss: 0.0401 - val_loss: 0.0741 - 2s/epoch - 127ms/step\n",
      "Epoch 14/50\n",
      "12/12 - 2s - loss: 0.0391 - val_loss: 0.0774 - 2s/epoch - 130ms/step\n",
      "Epoch 15/50\n",
      "12/12 - 2s - loss: 0.0383 - val_loss: 0.0745 - 2s/epoch - 135ms/step\n",
      "Epoch 16/50\n",
      "12/12 - 2s - loss: 0.0375 - val_loss: 0.0727 - 2s/epoch - 139ms/step\n",
      "Epoch 17/50\n",
      "12/12 - 2s - loss: 0.0362 - val_loss: 0.0760 - 2s/epoch - 138ms/step\n",
      "Epoch 18/50\n",
      "12/12 - 2s - loss: 0.0355 - val_loss: 0.0683 - 2s/epoch - 135ms/step\n",
      "Epoch 19/50\n",
      "12/12 - 2s - loss: 0.0343 - val_loss: 0.0766 - 2s/epoch - 135ms/step\n",
      "Epoch 20/50\n",
      "12/12 - 2s - loss: 0.0329 - val_loss: 0.0716 - 2s/epoch - 133ms/step\n",
      "Epoch 21/50\n",
      "12/12 - 2s - loss: 0.0312 - val_loss: 0.0713 - 2s/epoch - 136ms/step\n",
      "Epoch 22/50\n",
      "12/12 - 2s - loss: 0.0295 - val_loss: 0.0660 - 2s/epoch - 136ms/step\n",
      "Epoch 23/50\n",
      "12/12 - 2s - loss: 0.0277 - val_loss: 0.0650 - 2s/epoch - 135ms/step\n",
      "Epoch 24/50\n",
      "12/12 - 2s - loss: 0.0253 - val_loss: 0.0634 - 2s/epoch - 136ms/step\n",
      "Epoch 25/50\n",
      "12/12 - 2s - loss: 0.0234 - val_loss: 0.0589 - 2s/epoch - 137ms/step\n",
      "Epoch 26/50\n",
      "12/12 - 2s - loss: 0.0230 - val_loss: 0.0566 - 2s/epoch - 136ms/step\n",
      "Epoch 27/50\n",
      "12/12 - 2s - loss: 0.0203 - val_loss: 0.0527 - 2s/epoch - 135ms/step\n",
      "Epoch 28/50\n",
      "12/12 - 2s - loss: 0.0184 - val_loss: 0.0497 - 2s/epoch - 139ms/step\n",
      "Epoch 29/50\n",
      "12/12 - 2s - loss: 0.0173 - val_loss: 0.0484 - 2s/epoch - 132ms/step\n",
      "Epoch 30/50\n",
      "12/12 - 2s - loss: 0.0163 - val_loss: 0.0451 - 2s/epoch - 133ms/step\n",
      "Epoch 31/50\n",
      "12/12 - 2s - loss: 0.0158 - val_loss: 0.0436 - 2s/epoch - 139ms/step\n",
      "Epoch 32/50\n",
      "12/12 - 2s - loss: 0.0151 - val_loss: 0.0439 - 2s/epoch - 139ms/step\n",
      "Epoch 33/50\n",
      "12/12 - 2s - loss: 0.0149 - val_loss: 0.0419 - 2s/epoch - 136ms/step\n",
      "Epoch 34/50\n",
      "12/12 - 2s - loss: 0.0143 - val_loss: 0.0409 - 2s/epoch - 137ms/step\n",
      "Epoch 35/50\n",
      "12/12 - 2s - loss: 0.0141 - val_loss: 0.0405 - 2s/epoch - 139ms/step\n",
      "Epoch 36/50\n",
      "12/12 - 2s - loss: 0.0136 - val_loss: 0.0408 - 2s/epoch - 138ms/step\n",
      "Epoch 37/50\n",
      "12/12 - 2s - loss: 0.0134 - val_loss: 0.0394 - 2s/epoch - 137ms/step\n",
      "Epoch 38/50\n",
      "12/12 - 2s - loss: 0.0135 - val_loss: 0.0400 - 2s/epoch - 139ms/step\n",
      "Epoch 39/50\n",
      "12/12 - 2s - loss: 0.0131 - val_loss: 0.0390 - 2s/epoch - 139ms/step\n",
      "Epoch 40/50\n",
      "12/12 - 2s - loss: 0.0126 - val_loss: 0.0398 - 2s/epoch - 141ms/step\n",
      "Epoch 41/50\n",
      "12/12 - 2s - loss: 0.0125 - val_loss: 0.0389 - 2s/epoch - 140ms/step\n",
      "Epoch 42/50\n",
      "12/12 - 2s - loss: 0.0123 - val_loss: 0.0397 - 2s/epoch - 137ms/step\n",
      "Epoch 43/50\n",
      "12/12 - 2s - loss: 0.0120 - val_loss: 0.0378 - 2s/epoch - 134ms/step\n",
      "Epoch 44/50\n",
      "12/12 - 2s - loss: 0.0119 - val_loss: 0.0375 - 2s/epoch - 136ms/step\n",
      "Epoch 45/50\n",
      "12/12 - 2s - loss: 0.0118 - val_loss: 0.0373 - 2s/epoch - 137ms/step\n",
      "Epoch 46/50\n",
      "12/12 - 2s - loss: 0.0119 - val_loss: 0.0378 - 2s/epoch - 136ms/step\n",
      "Epoch 47/50\n",
      "12/12 - 2s - loss: 0.0113 - val_loss: 0.0371 - 2s/epoch - 139ms/step\n",
      "Epoch 48/50\n",
      "12/12 - 2s - loss: 0.0109 - val_loss: 0.0372 - 2s/epoch - 143ms/step\n",
      "Epoch 49/50\n",
      "12/12 - 2s - loss: 0.0109 - val_loss: 0.0385 - 2s/epoch - 140ms/step\n",
      "Epoch 50/50\n",
      "12/12 - 2s - loss: 0.0111 - val_loss: 0.0379 - 2s/epoch - 144ms/step\n"
     ]
    },
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='567ccd06-21f4-4e76-96f8-529f6153ca28'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to .\\Experiments\\4years_cal\\models\\mtl_i118_lstm8_f_o1\n",
      "Training time: 1 min\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "experiments = [\"4years_cal\"]\n",
    "models = {\n",
    "    # \"ResNet\": [8,2],\n",
    "    # \"Res-LSTM\":[8,2],\n",
    "    \"LSTM\":[8],\n",
    "    # \"GRU\": [8],\n",
    "    # \"Res-GRU\":[8,2],\n",
    "    # \"Transformer\":[8,2]  # this seems like its taking something like 27h to train!!! 2000s per epoch\n",
    "}\n",
    "for experiment in experiments:\n",
    "    print(\"experiment: \", experiment)\n",
    "\n",
    "    # create folders to save results\n",
    "    result_folders = ['models', 'results', 'images']\n",
    "    for result_folder in result_folders:\n",
    "        folder_path = os.path.join(local_root_path, \"Experiments\", experiment, result_folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    train_X = pd.read_csv(os.path.join(\"Experiments\", experiment, \"train_X.csv\"), index_col=0, compression=compression_opts)\n",
    "    train_Y = pd.read_csv(os.path.join(\"Experiments\", experiment, \"train_Y.csv\"), index_col=0, compression=compression_opts)\n",
    "    test_X = pd.read_csv(os.path.join(\"Experiments\", experiment, \"test_X.csv\"), index_col=0, compression=compression_opts)\n",
    "    test_Y = pd.read_csv(os.path.join(\"Experiments\", experiment, \"test_Y.csv\"), index_col=0, compression=compression_opts)\n",
    "\n",
    "    for  model_type, num_neurons_multiplier in models.items():\n",
    "        start = time.time()\n",
    "        model_str_def = build_model_string(model_type, num_neurons_multiplier)\n",
    "\n",
    "        full_model_str_def = 'i%d_' % (ndays + nwindows) + model_str_def\n",
    "\n",
    "        model_path_prefix = \"mtl_%s\" % (full_model_str_def)\n",
    "\n",
    "        print(\"model_str_def: %s\" % model_str_def)\n",
    "        model, xscaler, yscaler = build_or_load_model(model_path_prefix, full_model_str_def, num_neurons_multiplier, output_shape=train_Y.shape)\n",
    "\n",
    "        epochs = 50\n",
    "\n",
    "        print(\"Model summary:\")\n",
    "        print(model.summary())\n",
    "\n",
    "        if(xscaler is None or yscaler is None):\n",
    "            print(\"Creating new scalers\")\n",
    "\n",
    "        xscaler, yscaler = annutils.create_or_update_xyscaler(xscaler, yscaler, train_X, train_Y)\n",
    "        print(\"Xscaler Min[0]: %s\" % xscaler.min_val[0])\n",
    "        print(\"Xscaler Max[0]: %s\" % xscaler.max_val[0])\n",
    "\n",
    "        scaled_X = xscaler.transform(train_X)\n",
    "        scaled_Y = yscaler.transform(train_Y)\n",
    "\n",
    "        scaled_test_X = xscaler.transform(test_X)\n",
    "        scaled_test_Y = yscaler.transform(test_Y)\n",
    "\n",
    "        history = model.fit(\n",
    "            scaled_X,\n",
    "            scaled_Y,\n",
    "            epochs=epochs,\n",
    "            batch_size=128,\n",
    "            validation_data=(scaled_test_X, scaled_test_Y),\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\", patience=50, mode=\"min\", restore_best_weights=True),\n",
    "                tensorboard_cb\n",
    "            ],\n",
    "            verbose=2,\n",
    "        )\n",
    "\n",
    "        plot_history(history)\n",
    "\n",
    "        model_savepath = os.path.join(local_root_path, \"Experiments\", experiment, 'models', model_path_prefix)\n",
    "        # tf.saved_model.save(model, model_savepath)\n",
    "        annutils.save_model(model_savepath, model, xscaler, yscaler)\n",
    "        print('Model saved to %s' % model_savepath)\n",
    "        print('Training time: %d min' % ((time.time() - start) / 60))\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
